{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ben Trevett 의 [Simple Sentiment Analysis](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb) 튜토리얼을 한글 데이터셋에 적용해보는 연습이다. 데이터셋은 [네이버 영화 평점 데이터](https://github.com/e9t/nsmc)을 이용한다.\n",
    "\n",
    "이 튜토리얼에서는 RNN 모델을 이용하여 문장을 순차적으로 입력한 후 최종 hidden vector를 이용하여 문장이 긍정적인지 혹은 부정적인지 판단한다.\n",
    "\n",
    "먼저 필요한 패키지와 랜덤 시드를 설정하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "`Field`를 지정하자. 우리는 한글 데이터를 다루므로 토크나이저로 `spaCy`를 쓸 수가 없다. 여기서는 [KoNLPy](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)의 은전한닢 tokenizer를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=mecab.morphs)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtext`에 내장된 데이터셋을 이용하는 게 아니므로 각 컬럼별로 해당하는 `Field`를 지정해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'text': ('text',TEXT), 'label': ('label',LABEL)}\n",
    "# dictionary 형식은 {csv컬럼명 : (데이터 컬럼명, Field이름)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.TabularDataset.splits(\n",
    "                            path = 'data',\n",
    "                            train = 'train_data.csv',\n",
    "                            test = 'test_data.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields,  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 데이터는 다음과 같은 형태이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': ['아', '더', '빙', '.', '.', '진짜', '짜증', '나', '네요', '목소리'],\n",
       "  'label': '0'},\n",
       " {'text': ['흠',\n",
       "   '.',\n",
       "   '..',\n",
       "   '포스터',\n",
       "   '보고',\n",
       "   '초딩',\n",
       "   '영화',\n",
       "   '줄',\n",
       "   '.',\n",
       "   '...',\n",
       "   '오버',\n",
       "   '연기',\n",
       "   '조차',\n",
       "   '가볍',\n",
       "   '지',\n",
       "   '않',\n",
       "   '구나'],\n",
       "  'label': '1'})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[0]), vars(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터의 갯수는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 수 : 150000\n",
      "테스트 데이터 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print(f'훈련 데이터 수 : {len(train_data)}')\n",
    "print(f'테스트 데이터 수 : {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에 검증 데이터가 따로 주어져 있지 않으므로 생성해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 수 : 105000\n",
      "검증 데이터 수 : 45000\n",
      "테스트 데이터 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "print(f'훈련 데이터 수 : {len(train_data)}')\n",
    "print(f'검증 데이터 수 : {len(valid_data)}')\n",
    "print(f'테스트 데이터 수 : {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원 튜토리얼에서는 단어를 다짜고짜 25,000개로 끊는데, 일단 총 단어가 몇 개인지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45963"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data)\n",
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이중 최소 두 번 이상 등장하는 단어의 갯수를 세보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25210"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=2)\n",
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 정도면 그냥 25,000개로 끊어도 될 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT 단어장의 갯수 : 25002\n",
      "LABEL 단어장의 갯수 : 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEXT 단어장의 갯수 : {len(TEXT.vocab)}\")\n",
    "print(f\"LABEL 단어장의 갯수 : {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<unk>`와 `<pad>` 토큰이 추가되어 있으므로 단어의 갯수가 25,002개이다. 이제 최빈 단어들이 어떤 것인지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 112232), ('이', 51194), ('는', 46784), ('영화', 40412), ('다', 38942), ('고', 33023), ('하', 31175), ('도', 23975), ('의', 23819), ('가', 23360), ('은', 21871), ('에', 21472), ('을', 21007), ('보', 17937), ('한', 17744), ('..', 16006), (',', 15682), ('게', 15512), ('들', 15013), ('!', 13573)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어와 인덱스 사이 매핑도 확인해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '.', '이', '는', '영화', '다', '고', '하', '도']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'0': 0, '1': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `BucketIterator`를 이용하여 데이터 생성자를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    # 원래 튜토리얼은 아래 두줄이 없는데 에러가 나서 추가\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 데이터의 크기를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68, 64])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator)).text.shape\n",
    "# 문장의 길이 * 배치 사이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성\n",
    "\n",
    "바닐라 RNN을 이용하여 간단한 모델을 생성한다. 모델의 각 input/output 벡터의 사이즈는 다음과 같다.\n",
    "\n",
    "* `text` : `[sentence length, batch size]`\n",
    "* `embedded` : `[sentence length, batch size, embedding dim]`\n",
    "* `output` : `[sentence length, batch size, hidden dim]`\n",
    "* `hidden` : `[1, batch size, hidden dim]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text : [sent_len, batch_size]\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded : [sent_len, batch_size, emb_dim]\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # output : [sent_len, batch_size, hidden_dim]\n",
    "        # hidden : [1, batch_size, hidden_dim]\n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0)) # [batch_size, output_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 하이퍼파라미터를 다음과 같이 설정한 후 불러오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델의 파라미터수는 다음과 같이 추출할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 2,592,105 개의 파라미터를 가지고 있다.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'이 모델은 {count_parameters(model):,} 개의 파라미터를 가지고 있다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "가장 기초적인 SGD 옵티마이저를 이용하여 모델을 훈련시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수는 `binary cross entropy with logits`로 하자. 이 함수는 임의의 실수를 입력으로 받아서 sigmoid 함수를 취해 0과 1 사이의 값으로 변환한 뒤 `label`과의 `binary cross entropy`를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델과 손실함수를 GPU에 올리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 평가를 위해 임의의 실수를 0과 1 두 정수 중 하나로 변환하는 함수를 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds,y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델의 훈련과 평가를 위한 함수를 만들자.\n",
    "\n",
    "model의 output size는 `[batch_size, output_dim]`인데, output_dim = 1 이므로 이 차원을 없애줘야 `label`과 비교할 수 있다. 따라서 `squeeze(1)`를 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train() # 이 모델은 상관없음\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() # tensor에 item()을 취하면 value를 반환\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 위한 함수는 그래디언트 업데이트를 하지 않아야 하므로 `with torch.no_grad():` 구문으로 감싸도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval() # 이 모델은 상관없음\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에폭마다 걸린 훈련시간을 측정하는 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 실제로 훈련을 시켜보자. 검증셋의 손실이 개선되면 모델을 저장하도록 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.693 | Train Acc: 49.96%\n",
      "\t  Val. Loss: 0.694 |  Val. Acc: 51.81%\n",
      "Epoch: 02 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.693 | Train Acc: 50.06%\n",
      "\t  Val. Loss: 0.694 |  Val. Acc: 52.10%\n",
      "Epoch: 03 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.693 | Train Acc: 50.07%\n",
      "\t  Val. Loss: 0.693 |  Val. Acc: 52.30%\n",
      "Epoch: 04 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.693 | Train Acc: 50.19%\n",
      "\t  Val. Loss: 0.693 |  Val. Acc: 52.39%\n",
      "Epoch: 05 | Epoch Time: 0m 7s\n",
      "\t Train Loss: 0.693 | Train Acc: 50.10%\n",
      "\t  Val. Loss: 0.693 |  Val. Acc: 52.40%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:0.2f}%')\n",
    "    print(f'\\t  Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실상 훈련이 거의 되지 않는 것을 알 수 있다. 이는 모델의 성능이 좋지 않기 떄문인데, 이 튜토리얼에서 차차 개선해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로, 검증 셋에서 가장 좋은 결과를 받은 모델 기준으로 테스트셋의 결과를 측정해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.693 | Test Acc: 52.00%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
